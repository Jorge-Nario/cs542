{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0879700966315ddbd46fc66f18f49a4e8596e089"
      },
      "cell_type": "code",
      "source": "def f(x):\n    print(x)\n    params = { 'task': 'train', 'boosting_type': 'dart', 'objective': 'binary', 'learning_rate': x[0],\n        'num_leaves': x[1], 'min_data_in_leaf': x[2], 'num_iteration': x[3], 'max_bin': x[4],'verbose': 1 }\n    \n    gbm = lgb.train(params, train_data, num_boost_round=100,valid_sets=test_data, early_stopping_rounds=5)\n            \n    print(type(gbm.predict(X_test, num_iteration=gbm.best_iteration)[0]),type(up_test.astype(int)[0]))\n    \n    print('score: ', mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float)))\n    \n    return mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float))\n\nspaces = [ (0.19, 0.20), (2450, 2600), (210, 230), (310, 330), (200, 220) ]\n\n# run optimization\nfrom skopt import gp_minimize, plot_convergence\nresiduals = gp_minimize( f, spaces, acq_func=\"EI\", n_calls=10) \n\nprint(residuals.x)\nplot_convergence(residuals)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}