{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport gc\nfrom sklearn.preprocessing import StandardScaler\nfrom datetime import datetime, timedelta\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout, LSTM, GRU, Activation\nfrom keras.losses import mse",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74b423cb9e99fe712ae6e69b0a44d5fb2eac53bd"
      },
      "cell_type": "code",
      "source": "from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a4b6b6f9f3ddaa996fbeb73ac9098c9e46d24b0"
      },
      "cell_type": "code",
      "source": "(market_data, news_data) = env.get_training_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3874a5ababf7ecee0899abdf55ca9d0da8918663"
      },
      "cell_type": "code",
      "source": "start = datetime(2009, 1, 1, 0, 0, 0).date()\nmarket_data = market_data.loc[market_data['time'].dt.date >= start].reset_index(drop=True)\n\ndel news_data\ngc.collect()\n\nmarket_data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e3f61d3278fd7ed124fbf5a29bfdca657fb743e"
      },
      "cell_type": "code",
      "source": "def market_data_preprocessing(market_data, cols):\n    \n    market_data['time'] = market_data['time'].dt.floor('1D')\n    \n    market_data.loc[:, cols] = market_data.loc[:, cols].fillna(0)\n    \n    for i in range(len(cols)):\n        market_data = market_data[np.abs(market_data[cols[i]]-market_data[cols[i]].mean()) <= (3 * market_data[cols[i]].std())]\n        \n    market_data.returnsOpenNextMktres10 = market_data.returnsOpenNextMktres10.clip(-1, 1)\n    \n    market_data['label'] = market_data.returnsOpenNextMktres10.map(lambda x: 0 if x < 0 else 1)\n    \n    market_data['assetCodeSplit'] = market_data['assetCode']\n    \n    map_split = {}\n    for i in market_data['assetCode'].unique():\n        a, splits = i.split('.')\n        map_split[i] = splits\n    market_data['assetCodeSplit'] = market_data['assetCodeSplit'].map(map_split)\n    \n    one_hot_df = pd.get_dummies(market_data['assetCodeSplit'].astype(str))\n    market_data.drop(columns = ['assetCodeSplit'], inplace=True)\n    market_data = pd.concat([market_data, one_hot_df], axis=1)\n    \n    return market_data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4cf6dd777a2312718a444c66eedde5a37cc4b94d"
      },
      "cell_type": "code",
      "source": "market_data = market_data_preprocessing(market_data, [col for col in market_data.columns if col not in ['universe', 'time', 'assetCode', 'assetName']])\nmarket_data.sort_values(by=['time'], inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94fdb0a8978c7ae54e233207097979ffc48a2418"
      },
      "cell_type": "code",
      "source": "cols = [col for col in market_data.columns if col not in ['time','assetCode', 'universe', 'label', 'assetName',\n                                                               'assetCode_exchange_A', 'assetCode_exchange_N', 'assetCode_exchange_O',\n                                                               'assetCode_exchange_OB', 'assetCode_exchange_UNKNOWN', 'returnsOpenNextMktres10']]\nstd_scaler = StandardScaler(copy=False)\nmarket_data[cols] = market_data[cols].fillna(0)\nmarket_data.loc[:, cols] = std_scaler.fit_transform(market_data.loc[:, cols])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "492d4352c467b5619b7b08b6193405bd0c5f046b"
      },
      "cell_type": "code",
      "source": "class SequenceGenerator:\n    def __init__(self, market_data, cols, train=True):\n        self.market_data = market_data\n        self.cols = cols\n        self.train = train\n        \n        self.batch_size = 100000\n        self.window = 10\n\n    def generate(self):\n        \n        while True:\n            \n            X, y, returns, date, universe = [], [], [], [], []\n            \n            for a, data in self.market_data.groupby(['assetCode'], sort=False):\n                \n                data = data.sort_values(by=['time'])\n                num_sequences = data.shape[0] - self.window \n                \n                for seq in range(num_sequences):\n    \n                    returns.append(data.returnsOpenNextMktres10.iloc[seq+self.window-1])\n                    date.append(data.time.iloc[seq+self.window-1])\n                    universe.append(data.universe.iloc[seq+self.window-1])\n                    X.append(data[self.cols].iloc[seq:seq+self.window].values)\n                    y.append(data.label.iloc[seq+self.window-1])\n                    \n                    if len(X) == self.batch_size: \n                        X_, y_,returns_, date_, universe_ = np.array(X), np.array(y), np.array(returns),np.array(date), np.array(universe)\n                        X, y, returns, date, universe = [], [], [], [], []\n                        \n                        if self.train:\n                            yield X_, y_\n                        else:\n                            yield X_, y_, returns_, date_, universe_\n                            \n    def steps(self):\n        # get number of steps per epoch\n        steps = 0\n        for _, data in self.market_data.groupby(['assetCode'], sort=False):\n            num_sequences = data.shape[0] - self.window \n            steps += num_sequences // self.batch_size\n        return steps",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b5d22e5b6ca32b9153542542878da46fa207678"
      },
      "cell_type": "code",
      "source": "def split(*market_data, test_size=0.25):\n    splits = []\n    for i in range(len(market_data)):\n        limit = int(len(market_data[i]) * (1 - test_size))\n        splits.append(data[limit+1000:].copy())\n        splits.append(data[:limit].copy())\n    return sets\n\ntrain_df, val_df = split(market_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6601c3a6010927d6695c3962a92643f528e51810"
      },
      "cell_type": "code",
      "source": "cols = [col for col in market_data.columns if col not in ['time','assetCode', 'universe', 'label', 'assetName', 'returnsOpenNextMktres10']]\ntrain_gen = SequenceGenerator(train_df, cols)\ntest_gen = SequenceGenerator(val_df, cols)\ntrain_steps = train_gen.steps()\ntest_steps = test_gen.steps()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a5a3053f50bda5631346660cfd6a2a64f9f9f16"
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(LSTM(128, input_shape=(10, len(cols))))\nmodel.add(Activation('relu'))\nmodel.add(Dense(64))\nmodel.add(Activation('tanh'))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(optimizer='adam',loss='mse', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e13eac9aefbe805a5a68d8df3465c887f078a7a5"
      },
      "cell_type": "code",
      "source": "check_point = ModelCheckpoint('model.hdf5',verbose=True, save_best_only=True)\nearly_stop = EarlyStopping(patience=5,verbose=True)\nmodel.fit_generator(train_gen.generate(), validation_data=test_gen.generate(),epochs=1,steps_per_epoch=train_steps, validation_steps=test_steps,callbacks=[early_stop,check_point]) ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
