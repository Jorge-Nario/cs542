{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport numpy as np\nimport lightgbm as lgb\nimport pandas as pd\nfrom kaggle.competitions import twosigmanews\nimport matplotlib.pyplot as plt\nimport random\nfrom datetime import datetime, date\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport time\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['marketdata_sample.csv', 'news_sample.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "env = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train, news_train = market_train_df.copy(), news_train_df.copy()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loading the data... This could take a minute.\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "42a9f13b3bff34871360964817d8dc43bb3c2089"
      },
      "cell_type": "code",
      "source": "def populate(data):\n    for i in data.columns:\n        if (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        elif data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        else:\n            pass\n        \n    return data\n\nmarket_train_df = populate(market_train_df)\n\ndef data_prep(market_dataset):\n    market_dataset.time = market_dataset.time.dt.date\n    params = {k: v for v, k in enumerate(market_dataset['assetCode'].unique())}\n    market_dataset['assetCodeT'] = market_dataset['assetCode'].map(params)\n    \n    market_dataset = market_dataset.dropna(axis=0)\n    \n    return market_train\n\nmarket_train = data_prep(market_train_df)\n\n# check the shape\nprint(market_train.shape)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(4072956, 17)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d34749960065885416563c42ae781ae5e1bced6"
      },
      "cell_type": "code",
      "source": "market_dataset = market_dataset.loc[market_dataset['time']>=date(2009, 1, 1)]\nup = market_train.returnsOpenNextMktres10 >= 0\nfcol = [code for code in market_train if code not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n\nX = market_dataset[fcol].values\nup = up.values\nr = market_dataset.returnsOpenNextMktres10.values\n\n# Normalizing\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\n\nX = 1 - ((maxs - X) / rng)\n\nX_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.25, random_state=99)\n\ntrain_data = lgb.Dataset(X_train, label=up_train.astype(int))\ntest_data = lgb.Dataset(X_test, label=up_test.astype(int))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79fc1cff9bf8ce5790bd12861156e9870854f175"
      },
      "cell_type": "code",
      "source": "#These were found from seperate file -- see explor.py\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\n\nparams_1 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n        'num_iteration': x_1[3],\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \n    \n#prediction\ndays = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\n\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days += 1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    t = time.time()\n    market_obs_df = data_prep(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n    prediction_time += time.time() -t\n    \n    t = time.time()\n\n    confidence = lp\n    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n    \nenv.write_submission_file()\nsub  = pd.read_csv(\"submission.csv\")",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:116: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "[1]\tvalid_0's binary_logloss: 0.690737\nTraining until validation scores don't improve for 5 rounds.\n[2]\tvalid_0's binary_logloss: 0.689224\n[3]\tvalid_0's binary_logloss: 0.688185\n[4]\tvalid_0's binary_logloss: 0.687514\n[5]\tvalid_0's binary_logloss: 0.687052\n[6]\tvalid_0's binary_logloss: 0.686761\n[7]\tvalid_0's binary_logloss: 0.686554\n[8]\tvalid_0's binary_logloss: 0.686597\n[9]\tvalid_0's binary_logloss: 0.686394\n[10]\tvalid_0's binary_logloss: 0.686249\n[11]\tvalid_0's binary_logloss: 0.686118\n[12]\tvalid_0's binary_logloss: 0.686102\n[13]\tvalid_0's binary_logloss: 0.686038\n[14]\tvalid_0's binary_logloss: 0.685929\n[15]\tvalid_0's binary_logloss: 0.685906\n[16]\tvalid_0's binary_logloss: 0.685812\n[17]\tvalid_0's binary_logloss: 0.685791\n[18]\tvalid_0's binary_logloss: 0.685715\n[19]\tvalid_0's binary_logloss: 0.685565\n[20]\tvalid_0's binary_logloss: 0.685433\n[21]\tvalid_0's binary_logloss: 0.685415\n[22]\tvalid_0's binary_logloss: 0.685392\n[23]\tvalid_0's binary_logloss: 0.685356\n[24]\tvalid_0's binary_logloss: 0.68538\n[25]\tvalid_0's binary_logloss: 0.685401\n[26]\tvalid_0's binary_logloss: 0.685304\n[27]\tvalid_0's binary_logloss: 0.685239\n[28]\tvalid_0's binary_logloss: 0.685174\n[29]\tvalid_0's binary_logloss: 0.685187\n[30]\tvalid_0's binary_logloss: 0.685113\n[31]\tvalid_0's binary_logloss: 0.685091\n[32]\tvalid_0's binary_logloss: 0.685133\n[33]\tvalid_0's binary_logloss: 0.685179\n[34]\tvalid_0's binary_logloss: 0.685234\n[35]\tvalid_0's binary_logloss: 0.685162\n[36]\tvalid_0's binary_logloss: 0.685066\n[37]\tvalid_0's binary_logloss: 0.685122\n[38]\tvalid_0's binary_logloss: 0.685155\n[39]\tvalid_0's binary_logloss: 0.685174\n[40]\tvalid_0's binary_logloss: 0.685181\n[41]\tvalid_0's binary_logloss: 0.685126\nEarly stopping, best iteration is:\n[36]\tvalid_0's binary_logloss: 0.685066\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "You can only call `get_prediction_days` once.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d46d635a7616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmarket_obs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_obs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_template_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mn_days\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_days\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/kaggle/lib/kaggle/competitions/twosigmanews/env.py\u001b[0m in \u001b[0;36mget_prediction_days\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mTwoSigmaNewsEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_var00\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You can only call `get_prediction_days` once.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: You can only call `get_prediction_days` once."
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "502f85ff2ecc1ed50e96e7fe072dfee1eb235e5a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}